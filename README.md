# Deep-Learning-based-Image-Matting

The script 'depth model' can create bokeh (portrait mode) like effect on images. This script uses depth perception to separate the foreground and background. Instead of setting an arbitirary threshold value for depth perception (in the generated depth map, everything beyond a threshold value is considered as background), the threshold is set by detecting faces of the subject/s present in the image. The apparent depth of subject from the depth map is used as a the threshold. Depth maps are generated using pretrained MiDaS model (https://pytorch.org/hub/intelisl_midas_v2/) and face recognition is performed using 'Face Haar Cascade' in OpenCV.

Apart from being functional only when a face is detected, this method has another drawback in terms of pixel accurate segmentation between the subject and the background. This can be fixed by training yet another VGG16 based matting model which can be used as a final step for fine tuning the foreground segmentation.
